{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2 - Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pip3 install tensorflow # please uncomment for first time\n",
    "# pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alex/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the needed packages\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For CNN layers and model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# dont show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare glabal variables\n",
    "(x_train, y_train, x_test, y_test) = [0 ,0 ,0 , 0]\n",
    "model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() :\n",
    "    # Get mnist data set and split to train and test\n",
    "    global x_train, y_train, x_test, y_test\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data() :\n",
    "    # Reshape the datasets from 3 dim to 4 dim - required\n",
    "    global x_train, y_train, x_test, y_test\n",
    "\n",
    "    #x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    #x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data() :\n",
    "    # Convert to float\n",
    "    global x_train, y_train, x_test, y_test\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Create model\n",
    "    global model\n",
    "    model = Sequential() \n",
    "    model.add(Dense(784, activation=tf.nn.relu, input_shape=(28 * 28,)   ))\n",
    "    model.add(Dense(784, activation=tf.nn.relu, input_shape=(28 * 28,)   ))\n",
    "\n",
    "    #model.add(Dense(1,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model() :\n",
    "    # Compile and train the model\n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x=x_train.reshape((60000, 28 * 28)), y=y_train, epochs=10, batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model() :\n",
    "    # Evaluate the model\n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "\n",
    "    model.evaluate(x_test.reshape((10000, 28 * 28)), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(image_index) :\n",
    "    # Predict image \n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "\n",
    "    \n",
    "    # Validate index must be < 10 000\n",
    "    if image_index > 10000 :\n",
    "        image_index = 25\n",
    "    image = x_test[image_index]\n",
    "    print(image.shape)\n",
    "\n",
    "    plt.imshow(image.reshape(28, 28),cmap='Greys')\n",
    "    pred = model.predict(image.reshape(1, 784))\n",
    "    print('The predected image is : ' , pred.argmax())\n",
    "\n",
    "    # printimage.reshape(28, 28))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN \n",
    "\n",
    "# 1 - Load Data\n",
    "load_data()\n",
    "\n",
    "# 2 - preprocess data\n",
    "pre_process_data()\n",
    "\n",
    "# 3 - normalize data\n",
    "normalize_data()\n",
    "\n",
    "# 4 - create model\n",
    "create_model()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alex/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/alex/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 5.2044 - accuracy: 0.2129\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 6.6315 - accuracy: 0.1070\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 6.6045 - accuracy: 0.1080\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 6.6136 - accuracy: 0.1065\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 6.6113 - accuracy: 0.1111\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 6.6302 - accuracy: 0.1039\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 6.6298 - accuracy: 0.1064\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 6.5841 - accuracy: 0.1110\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 6.5838 - accuracy: 0.1110\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 6.5911 - accuracy: 0.1099\n"
     ]
    }
   ],
   "source": [
    "# 5 - train model with x_train, y_train\n",
    "train_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 204us/step\n"
     ]
    }
   ],
   "source": [
    "# 6 - evaluate model\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "The predected image is :  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7 - predict an image by index ( < 10 000)\n",
    "predict_image(5) # specify image index in x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
