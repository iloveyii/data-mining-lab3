{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pip3 install tensorflow # please uncomment for first time\n",
    "# pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed packages\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For CNN layers and model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# dont show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare glabal variables\n",
    "(x_train, y_train, x_test, y_test) = [0 ,0 ,0 , 0]\n",
    "model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() :\n",
    "    # Get mnist data set and split to train and test\n",
    "    global x_train, y_train, x_test, y_test\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data() :\n",
    "    # Reshape the datasets from 3 dim to 4 dim - required\n",
    "    global x_train, y_train, x_test, y_test\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data() :\n",
    "    # Convert to float\n",
    "    global x_train, y_train, x_test, y_test\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    # Normalize the RGB codes - Divide by 255\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Create model\n",
    "    input_shape = (28, 28, 1)\n",
    "    global model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(128, activation=tf.nn.relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model() :\n",
    "    # Compile and train the model\n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x=x_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model() :\n",
    "    # Evaluate the model\n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "\n",
    "    model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(image_index) :\n",
    "    # Predict image \n",
    "    global x_train, y_train, x_test, y_test, model\n",
    "\n",
    "    \n",
    "    # Validate index must be < 10 000\n",
    "    if image_index > 10000 :\n",
    "        image_index = 25\n",
    "    image = x_test[image_index]\n",
    "    img_rows, img_cols, i = image.shape\n",
    "\n",
    "    plt.imshow(image.reshape(28, 28),cmap='Greys')\n",
    "    pred = model.predict(image.reshape(1, img_rows, img_cols, 1))\n",
    "    print('The predected image is : ' , pred.argmax())\n",
    "\n",
    "    # printimage.reshape(28, 28))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alex/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alex/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 22s 373us/step - loss: 0.2114 - accuracy: 0.9356\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 375us/step - loss: 0.0848 - accuracy: 0.9739\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0586 - accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0438 - accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s 372us/step - loss: 0.0360 - accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 382us/step - loss: 0.0294 - accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 379us/step - loss: 0.0256 - accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.0220 - accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 388us/step - loss: 0.0174 - accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0186 - accuracy: 0.9938\n",
      "10000/10000 [==============================] - 1s 103us/step\n"
     ]
    }
   ],
   "source": [
    "# RUN \n",
    "\n",
    "# 1 - Load Data\n",
    "load_data()\n",
    "\n",
    "# 2 - preprocess data\n",
    "pre_process_data()\n",
    "\n",
    "# 3 - normalize data\n",
    "normalize_data()\n",
    "\n",
    "# 4 - create model\n",
    "create_model()\n",
    "\n",
    "# 5 - train model with x_train, y_train\n",
    "train_model()\n",
    "\n",
    "# 6 - evaluate model\n",
    "evaluate_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predected image is :  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7 - predict an image by index ( < 10 000)\n",
    "predict_image(52) # specify image index in x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
